{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e87cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import griddly\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import wandb\n",
    "import skvideo.io\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgba2rgb\n",
    "from models.disentangle_network import DisentangleNetwork\n",
    "from ppo_ir_modules import EpisodicMemory\n",
    "from utils import wrap_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d33294",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112c0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_name):\n",
    "    env = wrap_env(env_name, max_frames=500, frame_stack=False, obs_shape=(84,84), test=True, punishment=1, no_ext=True)\n",
    "    env.enable_history(True)\n",
    "    env.seed(100)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87b33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"ut-rl-control/cen-rl/{}\"\n",
    "\n",
    "def load_config(run_id):\n",
    "    run = client.run(PATH.format(run_id))\n",
    "    config = run.config\n",
    "    return config\n",
    "\n",
    "def load_model(run_id, env, download=False):\n",
    "    run_path = PATH.format(run_id)\n",
    "    config = load_config(run_id)\n",
    "    \n",
    "    num_actions = min(10, env.action_space.n)\n",
    "    image_channels = env.observation_space.shape[0]\n",
    "    if config['IR_module'] == 'CTRL':\n",
    "        mask_network = DisentangleNetwork(image_channels, num_actions, config['ctrl_hidden_size'], config['ctrl_channels'], config['ctrl_latent_size'], config['ctrl_encoder_out']).to(device).eval()\n",
    "        combine_masks = False\n",
    "        model_name = 'disentanglement'\n",
    "    else:\n",
    "        raise ValueError('Model type not supported ({})'.format(config['IR_module']))\n",
    "\n",
    "    if download:\n",
    "        wandb.restore('{}_{}_network.pth'.format(model_name, run_id), run_path=run_path, replace=True)\n",
    "        \n",
    "    mask_network.load_state_dict(torch.load('{}_{}_network.pth'.format(model_name, run_id), map_location=device), strict=True)\n",
    "    # mask_network = torch.load('{}_{}_network.pth'.format(model_name, run_id), map_location=device)\n",
    "\n",
    "    return mask_network, combine_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c8e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-11-28 20:45:49.234] [info] Loading GDY file: /home/ocorcoll/projects/controllable-IR/gdy_envs/butterflies_spiders_easy.yml\n",
      "[2021-11-28 20:45:49.238] [info] Loading GDY file Version: 0.1.\n",
      "[2021-11-28 20:45:49.238] [info] Loading 5 objects...\n",
      "[2021-11-28 20:45:49.238] [info] Loading 5 actions...\n",
      "[2021-11-28 20:45:49.238] [info] Loading Environment...\n",
      "[2021-11-28 20:45:49.239] [info] Loaded 14 levels\n",
      "CNNDecoder(\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(128, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (11): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cen_run_id = '15dzfnb1'#'rqt6qopv'\n",
    "config = load_config(cen_run_id)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "env = make_env(config['env_name'])\n",
    "\n",
    "cen_network, cen_combine_masks = load_model(cen_run_id, env)\n",
    "config['combine_masks'] = cen_combine_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32962ba9-68a0-4dcd-8d5f-80476b140314",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['ngu_k_neighbors'] = 5\n",
    "episodic_memory = EpisodicMemory(config['ngu_mem'], config['ctrl_latent_size'], config['ngu_k_neighbors'], config['ir_eps'], config['ir_c'], max_sim=config['ir_max_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ae23c7-1718-4243-8fee-b606a21ee3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.01 1 2\n"
     ]
    }
   ],
   "source": [
    "print(config['ngu_k_neighbors'], config['ir_eps'], config['ir_c'], config['ir_max_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e6ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_video(frames, output_file='eval_video.mp4'):\n",
    "    fps = '12'\n",
    "    writer = skvideo.io.FFmpegWriter(output_file, \n",
    "        inputdict={'-r': fps},\n",
    "        outputdict={'-r': fps},\n",
    "    )\n",
    "\n",
    "    for frame in frames:\n",
    "        writer.writeFrame(frame)\n",
    "    writer.close()\n",
    "\n",
    "def mask_observation(observation, mask, threshold=0.03, use_negative=True):\n",
    "    if use_negative:\n",
    "        mask = np.abs(mask)\n",
    "\n",
    "    binary_mask = (mask >= threshold).astype(float) + 0.7\n",
    "    binary_mask = resize(binary_mask, observation.shape)\n",
    "    \n",
    "    image = observation * binary_mask\n",
    "    # image = np.concatenate([observation / 255., binary_mask], axis=-1)\n",
    "    # image = rgba2rgb(image)\n",
    "    # image = np.clip(image * 255, 0, 255).astype(np.uint8)\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a97336-bfcc-4054-9b4d-0ab1aa7f08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(episodic_memory, embedding):\n",
    "    if episodic_memory.num < episodic_memory.k_neighbors:\n",
    "        return 0, -1\n",
    "\n",
    "    test = np.array(embedding).ravel()[None, :]\n",
    "    dists = np.sum((test - episodic_memory.memory[:episodic_memory.num])**2, axis=1)\n",
    "    k_dist = np.partition(dists, episodic_memory.k_neighbors+1)[:episodic_memory.k_neighbors+1] if len(dists) > episodic_memory.k_neighbors+1 else np.sort(dists)[:episodic_memory.k_neighbors+1]\n",
    "    k_dist = np.delete(k_dist, k_dist.argmin()) if len(k_dist) > 1 else k_dist\n",
    "    \n",
    "    episodic_memory.running_sum += np.sum(k_dist)\n",
    "    episodic_memory.running_num += len(k_dist)\n",
    "    running_mean = episodic_memory.running_sum / episodic_memory.running_num\n",
    "    \n",
    "    dist_normalized = k_dist / max(running_mean, 1e-8)   # (running_mean if abs(running_mean - 0)>self.psi else self.psi )\n",
    "    dist_normalized = np.maximum(dist_normalized - episodic_memory.psi, 0)\n",
    "    dist_kernel = episodic_memory.eps / (episodic_memory.eps + dist_normalized)\n",
    "    \n",
    "    sim = np.sqrt(np.sum(dist_kernel)) + episodic_memory.C\n",
    "    score = 0 if sim >= episodic_memory.max_sim else 1 / sim\n",
    "    print(score, sim, dist_kernel, dist_normalized, k_dist)\n",
    "    return score, dist_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98be9340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 False 0 -1 tensor(15.2934)\n",
      "2 2 False 0 -1 tensor(15.2934)\n",
      "3 3 False 0 -1 tensor(0.8988)\n",
      "4 4 False 0 -1 tensor(15.1723)\n",
      "0 2.4349763635723707 [1.         1.         0.05654425 0.00261291] [0.         0.         0.16685264 3.81714736] [ 0.          0.          3.12832949 68.43660791]\n",
      "5 5 False 0 [0.         0.         0.16685264 3.81714736] tensor(15.2934)\n",
      "0.7513176869788201 1.3309948871577548 [0.03132238 0.0251673  0.0251673  0.0251673  0.00273334] [0.30926055 0.38734101 0.38734101 0.38734101 3.64853021] [ 5.91240369  7.36749541  7.36749541  7.36749541 68.14236105]\n",
      "6 6 False 0.7513176869788201 [0.30926055 0.38734101 0.38734101 0.38734101 3.64853021] tensor(1.2012)\n",
      "0 2.0706726812303433 [0.04144216 0.04144216 1.         0.04144216 0.0220135 ] [0.23130015 0.23130015 0.         0.23130015 0.44426664] [3.12832949 3.12832949 0.         3.12832949 5.91240369]\n",
      "7 7 False 0 [0.23130015 0.23130015 0.         0.23130015 0.44426664] tensor(15.1723)\n",
      "0 2.447925001109713 [1.         1.         0.03216227 0.03216227 0.03216227] [0.         0.         0.30092333 0.30092333 0.30092333] [0.         0.         3.12832949 3.12832949 3.12832949]\n",
      "8 8 False 0 [0.         0.         0.30092333 0.30092333 0.30092333] tensor(15.1723)\n",
      "0 2.005689581598209 [0.00286193 1.         0.00286193 0.00286193 0.00282574] [3.48414285 0.         3.48414285 3.48414285 3.52889866] [67.28008961  0.         67.28008961 67.28008961 68.14236105]\n",
      "9 9 False 0 [3.48414285 0.         3.48414285 3.48414285 3.52889866] tensor(0.8988)\n",
      "0.7115413235793031 1.405399752427095 [0.03636529 0.03636529 0.02762655 0.03636529 0.02762655] [0.2649875 0.2649875 0.3519707 0.2649875 0.3519707] [4.5965363  4.5965363  6.06115076 4.5965363  6.06115076]\n",
      "10 10 False 0.7115413235793031 [0.2649875 0.2649875 0.3519707 0.2649875 0.3519707] tensor(15.3456)\n",
      "0 2.0589860295137044 [0.03230481 1.         0.03230481 0.03230481 0.02453699] [0.29955146 0.         0.29955146 0.29955146 0.39754793] [4.5965363  0.         4.5965363  4.5965363  6.06115076]\n",
      "11 11 False 0 [0.29955146 0.         0.29955146 0.29955146 0.39754793] tensor(15.3456)\n",
      "0 2.0428564716191127 [1.         0.02301981 0.02301981 0.02301981 0.01849018] [0.         0.42440837 0.42440837 0.42440837 0.53082767] [0.         5.91240369 5.91240369 5.91240369 7.36749541]\n",
      "12 12 False 0 [0.         0.42440837 0.42440837 0.42440837 0.53082767] tensor(1.2012)\n",
      "0 2.4424659863538265 [0.02690271 1.         1.         0.02690271 0.02690271] [0.3617098 0.        0.        0.3617098 0.3617098] [4.5965363 0.        0.        4.5965363 4.5965363]\n",
      "13 13 False 0 [0.3617098 0.        0.        0.3617098 0.3617098] tensor(15.3456)\n",
      "0 2.4166198185188983 [0.00227057 1.         1.         0.00227057 0.00227057] [4.39418031 0.         0.         4.39418031 4.39418031] [67.28008961  0.          0.         67.28008961 67.28008961]\n",
      "14 14 False 0 [4.39418031 0.         0.         4.39418031 4.39418031] tensor(0.8988)\n",
      "0 2.733453464345968 [0.00243046 1.         1.         1.         0.00243046] [4.10445335 0.         0.         0.         4.10445335] [67.28008961  0.          0.          0.         67.28008961]\n",
      "15 15 False 0 [4.10445335 0.         0.         0.         4.10445335] tensor(0.8988)\n",
      "0 2.75082816835058 [0.03269964 1.         1.         1.         0.03269964] [0.29581379 0.         0.         0.         0.29581379] [4.5965363 0.        0.        0.        4.5965363]\n",
      "16 16 False 0 [0.29581379 0.         0.         0.         0.29581379] tensor(15.3456)\n",
      "0 2.4393856817629045 [0.02394371 1.         1.         0.02394371 0.02394371] [0.40764616 0.         0.         0.40764616 0.40764616] [5.91240369 0.         0.         5.91240369 5.91240369]\n",
      "17 17 False 0 [0.40764616 0.         0.         0.40764616 0.40764616] tensor(1.2012)\n",
      "0 3.0071580168525953 [0.0286833 1.        1.        1.        1.       ] [0.33863486 0.         0.         0.         0.        ] [4.5965363 0.        0.        0.        0.       ]\n",
      "18 18 False 0 [0.33863486 0.         0.         0.         0.        ] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "19 19 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 2.753282642679605 [1.         0.03700001 1.         1.         0.03700001] [0.         0.26027018 0.         0.         0.26027018] [0.         3.12832949 0.         0.         3.12832949]\n",
      "20 20 False 0 [0.         0.26027018 0.         0.         0.26027018] tensor(15.1723)\n",
      "0 3.00871360776059 [1.         1.         1.         0.03493036 1.        ] [0.         0.         0.         0.27628393 0.        ] [0.         0.         0.         3.12832949 0.        ]\n",
      "21 21 False 0 [0.         0.         0.         0.27628393 0.        ] tensor(15.1723)\n",
      "0 2.751115459904547 [1.         1.         1.         0.03320268 0.03320268] [0.         0.         0.         0.29118053 0.29118053] [0.         0.         0.         3.12832949 3.12832949]\n",
      "22 22 False 0 [0.         0.         0.         0.29118053 0.29118053] tensor(15.2934)\n",
      "0 2.7417807805597394 [1.         1.         1.         0.01690014 0.01690014] [0.         0.         0.         0.58171094 0.58171094] [0.         0.         0.         5.91240369 5.91240369]\n",
      "23 23 False 0 [0.         0.         0.         0.58171094 0.58171094] tensor(1.2012)\n",
      "0 3.007572147729257 [1.         1.         1.         1.         0.03034593] [0.        0.        0.        0.        0.3195335] [0.         0.         0.         0.         3.12832949]\n",
      "24 24 False 0 [0.        0.        0.        0.        0.3195335] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "25 25 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "26 26 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "27 27 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "28 28 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "29 29 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.0002916582579413 [1.         1.         1.         1.         0.00116672] [0.         0.         0.         0.         8.56105074] [ 0.          0.          0.          0.         67.28008961]\n",
      "30 30 False 0 [0.         0.         0.         0.         8.56105074] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "31 31 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "32 32 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "33 33 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "34 34 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.0027890292858146 [1.        1.        1.        1.        0.0111639] [0.         0.         0.         0.         0.88574465] [0.         0.         0.         0.         5.91240369]\n",
      "35 35 False 0 [0.         0.         0.         0.         0.88574465] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "36 36 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "37 37 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "38 38 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "39 39 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "40 40 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "41 41 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "42 42 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "43 43 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "44 44 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "45 45 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "46 46 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "47 47 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "48 48 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "49 49 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "50 50 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "51 51 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "52 52 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "53 53 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "54 54 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "55 55 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "56 56 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "57 57 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "58 58 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "59 59 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "60 60 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "61 61 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "62 62 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "63 63 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "64 64 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "65 65 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "66 66 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "67 67 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "68 68 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "69 69 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "70 70 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "71 71 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "72 72 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "73 73 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "74 74 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "75 75 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "76 76 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "77 77 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "78 78 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "79 79 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "80 80 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "81 81 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "82 82 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "83 83 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "84 84 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "85 85 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "86 86 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "87 87 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "88 88 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "89 89 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "90 90 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "91 91 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "92 92 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "93 93 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "94 94 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "95 95 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "96 96 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "97 97 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "98 98 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "99 99 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "100 100 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "101 101 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "102 102 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "103 103 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "104 104 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "105 105 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "106 106 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "107 107 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "108 108 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "109 109 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "110 110 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "111 111 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "112 112 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "113 113 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "114 114 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "115 115 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "116 116 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "117 117 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "118 118 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "119 119 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "120 120 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "121 121 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "122 122 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "123 123 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "124 124 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "125 125 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "126 126 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "127 127 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "128 128 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "129 129 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "130 130 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "131 131 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "132 132 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "133 133 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "134 134 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "135 135 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "136 136 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "137 137 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "138 138 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "139 139 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "140 140 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "141 141 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "142 142 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "143 143 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "144 144 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "145 145 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "146 146 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "147 147 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "148 148 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "149 149 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "150 150 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "151 151 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "152 152 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "153 153 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "154 154 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "155 155 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "156 156 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "157 157 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "158 158 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "159 159 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "160 160 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "161 161 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "162 162 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "163 163 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "164 164 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "165 165 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "166 166 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "167 167 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "168 168 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "169 169 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "170 170 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "171 171 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "172 172 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "173 173 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "174 174 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "175 175 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "176 176 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "177 177 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "178 178 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "179 179 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "180 180 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "181 181 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "182 182 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "183 183 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "184 184 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "185 185 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "186 186 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "187 187 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "188 188 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "189 189 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "190 190 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "191 191 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "192 192 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "193 193 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "194 194 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "195 195 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "196 196 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "197 197 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "198 198 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "199 199 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "200 200 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "201 201 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "202 202 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "203 203 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "204 204 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "205 205 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "206 206 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "207 207 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "208 208 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "209 209 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "210 210 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "211 211 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "212 212 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "213 213 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "214 214 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "215 215 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "216 216 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "217 217 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "218 218 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "219 219 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "220 220 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "221 221 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "222 222 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "223 223 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "224 224 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "225 225 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "226 226 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "227 227 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "228 228 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "229 229 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "230 230 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "231 231 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "232 232 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "233 233 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "234 234 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "235 235 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "236 236 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "237 237 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "238 238 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "239 239 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "240 240 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "241 241 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "242 242 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "243 243 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "244 244 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "245 245 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "246 246 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "247 247 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "248 248 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "249 249 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "250 250 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "251 251 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "252 252 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "253 253 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "254 254 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "255 255 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "256 256 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "257 257 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "258 258 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "259 259 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "260 260 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "261 261 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "262 262 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "263 263 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "264 264 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "265 265 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "266 266 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "267 267 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "268 268 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "269 269 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "270 270 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "271 271 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "272 272 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "273 273 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "274 274 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "275 275 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "276 276 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "277 277 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "278 278 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "279 279 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "280 280 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "281 281 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "282 282 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "283 283 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "284 284 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "285 285 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "286 286 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "287 287 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "288 288 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "289 289 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "290 290 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "291 291 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "292 292 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "293 293 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "294 294 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "295 295 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "296 296 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "297 297 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "298 298 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "299 299 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "300 300 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "301 301 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "302 302 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "303 303 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "304 304 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "305 305 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "306 306 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "307 307 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "308 308 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "309 309 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "310 310 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "311 311 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "312 312 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "313 313 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "314 314 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "315 315 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "316 316 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "317 317 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "318 318 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "319 319 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "320 320 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "321 321 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "322 322 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "323 323 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "324 324 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "325 325 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "326 326 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "327 327 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "328 328 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "329 329 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "330 330 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "331 331 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "332 332 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "333 333 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "334 334 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "335 335 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "336 336 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "337 337 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "338 338 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "339 339 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "340 340 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "341 341 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "342 342 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "343 343 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "344 344 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "345 345 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "346 346 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "347 347 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "348 348 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "349 349 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "350 350 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "351 351 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "352 352 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "353 353 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "354 354 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "355 355 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "356 356 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "357 357 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "358 358 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "359 359 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "360 360 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "361 361 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "362 362 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "363 363 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "364 364 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "365 365 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "366 366 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "367 367 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "368 368 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "369 369 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "370 370 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "371 371 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "372 372 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "373 373 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "374 374 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "375 375 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "376 376 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "377 377 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "378 378 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "379 379 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "380 380 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "381 381 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "382 382 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "383 383 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "384 384 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "385 385 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "386 386 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "387 387 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "388 388 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "389 389 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "390 390 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "391 391 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "392 392 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "393 393 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "394 394 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "395 395 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "396 396 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "397 397 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "398 398 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "399 399 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "400 400 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "401 401 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "402 402 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "403 403 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "404 404 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "405 405 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "406 406 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "407 407 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "408 408 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "409 409 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "410 410 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "411 411 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "412 412 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "413 413 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "414 414 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "415 415 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "416 416 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "417 417 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "418 418 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "419 419 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "420 420 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "421 421 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "422 422 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "423 423 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "424 424 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "425 425 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "426 426 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "427 427 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "428 428 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "429 429 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "430 430 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "431 431 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "432 432 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "433 433 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "434 434 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "435 435 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "436 436 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "437 437 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "438 438 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "439 439 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "440 440 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "441 441 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "442 442 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "443 443 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "444 444 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "445 445 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "446 446 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "447 447 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "448 448 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "449 449 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "450 450 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "451 451 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "452 452 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "453 453 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "454 454 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "455 455 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "456 456 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "457 457 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "458 458 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "459 459 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "460 460 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "461 461 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "462 462 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "463 463 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "464 464 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "465 465 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "466 466 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "467 467 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "468 468 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "469 469 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "470 470 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "471 471 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "472 472 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "473 473 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "474 474 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "475 475 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "476 476 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "477 477 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "478 478 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "479 479 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "480 480 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "481 481 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "482 482 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "483 483 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "484 484 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "485 485 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "486 486 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "487 487 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "488 488 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "489 489 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "490 490 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "491 491 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "492 492 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "493 493 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "494 494 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "495 495 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "496 496 False 0 [0. 0. 0. 0. 0.] tensor(1.2012)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "497 497 False 0 [0. 0. 0. 0. 0.] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "498 498 False 0 [0. 0. 0. 0. 0.] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "499 499 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "500 500 False 0 [0. 0. 0. 0. 0.] tensor(15.1723)\n",
      "1 1 False 0 -1 tensor(15.3456)\n",
      "2 2 False 0 -1 tensor(15.3456)\n",
      "3 3 False 0 -1 tensor(15.3456)\n",
      "4 4 False 0 -1 tensor(15.1723)\n",
      "0.9832541392521228 1.0170310605156612 [7.84459362e-05 7.05370287e-05 7.05370287e-05 7.05370287e-05] [127.46632933 141.75951008 141.75951008 141.75951008] [67.28008961 74.82393382 74.82393382 74.82393382]\n",
      "5 5 False 0.9832541392521228 [127.46632933 141.75951008 141.75951008 141.75951008] tensor(0.8988)\n",
      "0.9547341969489741 1.0474119427120983 [9.70473355e-04 3.97733486e-04 3.97733486e-04 3.97733486e-04\n",
      " 8.42185006e-05] [ 10.29424993  25.1324644   25.1324644   25.1324644  118.72875607] [ 5.91240369 14.42797208 14.42797208 14.42797208 68.14236105]\n",
      "6 6 False 0.9547341969489741 [ 10.29424993  25.1324644   25.1324644   25.1324644  118.72875607] tensor(1.2012)\n",
      "0 2.0001932833117473 [9.18261111e-05 9.18261111e-05 1.02121991e-04 1.00000000e+00\n",
      " 1.00829769e-04] [108.89148647 108.89148647  97.91210168   0.          99.16705998] [74.82393382 74.82393382 67.28008961  0.         68.14236105]\n",
      "7 7 False 0 [108.89148647 108.89148647  97.91210168   0.          99.16705998] tensor(0.8988)\n",
      "0 2.7325199878186854 [1.00000000e+00 1.00000000e+00 1.00000000e+00 1.14460077e-03\n",
      " 4.80907425e-04] [ 0.          0.          0.          8.72667072 20.78402289] [ 0.          0.          0.          6.06115076 14.42797208]\n",
      "8 8 False 0 [ 0.          0.          0.          8.72667072 20.78402289] tensor(15.3456)\n",
      "0 3.0002865565234016 [1.         1.         1.         1.         0.00114631] [0.         0.         0.         0.         8.71365733] [0.         0.         0.         0.         6.06115076]\n",
      "9 9 False 0 [0.         0.         0.         0.         8.71365733] tensor(15.3456)\n",
      "0 2.4143314748698064 [1.00000000e+00 1.00000000e+00 1.03894923e-04 1.15543971e-04\n",
      " 1.14081914e-04] [ 0.          0.         96.24109435 86.53713818 87.6463133 ] [ 0.          0.         74.82393382 67.28008961 68.14236105]\n",
      "10 10 False 0 [ 0.          0.         96.24109435 86.53713818 87.6463133 ] tensor(0.8988)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "11 11 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 2.002598788873117 [1.         0.00132547 0.00129295 0.00129295 0.00129295] [0.         7.53447693 7.72423416 7.72423416 7.72423416] [0.         5.91240369 6.06115076 6.06115076 6.06115076]\n",
      "12 12 False 0 [0.         7.53447693 7.72423416 7.72423416 7.72423416] tensor(15.1723)\n",
      "0 2.4156056256053318 [0.00130218 1.         1.         0.00130218 0.00133493] [7.66943938 0.         0.         7.66943938 7.48102687] [6.06115076 0.         0.         6.06115076 5.91240369]\n",
      "13 13 False 0 [7.66943938 0.         0.         7.66943938 7.48102687] tensor(15.1723)\n",
      "0.904756984500411 1.1052691685515756 [0.00172954 0.00254084 0.00254084 0.00254084 0.00172954] [5.77189447 3.92570424 3.92570424 3.92570424 5.77189447] [4.5965363  3.12832949 3.12832949 3.12832949 4.5965363 ]\n",
      "14 14 False 0.904756984500411 [5.77189447 3.92570424 3.92570424 3.92570424 5.77189447] tensor(15.2934)\n",
      "0 2.004688254532261 [0.00255345 0.00255345 1.         0.00255345 0.00173812] [3.90626272 3.90626272 0.         3.90626272 5.74332854] [3.12832949 3.12832949 0.         3.12832949 4.5965363 ]\n",
      "15 15 False 0 [3.90626272 3.90626272 0.         3.90626272 5.74332854] tensor(15.2934)\n",
      "0 2.41692649973156 [0.00256024 1.         1.         0.00256024 0.00256024] [3.89589113 0.         0.         3.89589113 3.89589113] [3.12832949 0.         0.         3.12832949 3.12832949]\n",
      "16 16 False 0 [3.89589113 0.         0.         3.89589113 3.89589113] tensor(15.2934)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "17 17 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 2.7335270598385506 [1.         1.         1.         0.00255803 0.00255803] [0.        0.        0.        3.8992528 3.8992528] [0.         0.         0.         3.12832949 3.12832949]\n",
      "18 18 False 0 [0.        0.        0.        3.8992528 3.8992528] tensor(15.1723)\n",
      "0 3.23606797749979 [1. 1. 1. 1. 1.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n",
      "19 19 False 0 [0. 0. 0. 0. 0.] tensor(15.3456)\n",
      "0 3.0006378842456063 [1.         1.         1.         1.         0.00255194] [0.         0.         0.         0.         3.90858147] [0.         0.         0.         0.         3.12832949]\n",
      "20 20 False 0 [0.         0.         0.         0.         3.90858147] tensor(15.1723)\n",
      "0 2.7321237179623066 [1.26287164e-04 1.00000000e+00 1.26287164e-04 1.00000000e+00\n",
      " 1.00000000e+00] [79.17461149  0.         79.17461149  0.          0.        ] [67.28008961  0.         67.28008961  0.          0.        ]\n",
      "21 21 False 0 [79.17461149  0.         79.17461149  0.          0.        ] tensor(0.8988)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67018/83583789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcen_controlled_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcen_normal_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrolled_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcen_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcen_controlled_mask_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcen_controlled_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cen_rl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/controllable-IR/models/disentangle_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation, action)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mhidden_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_observation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mcontrollable_effects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_controllable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mnormal_effects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_normal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontrollable_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_controllable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cen_rl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/controllable-IR/models/cnn_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cen_rl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cen_rl/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cen_rl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cen_rl/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    838\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    841\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_obs(obs):\n",
    "    if obs is None:\n",
    "        observation_raw = env.reset()\n",
    "    else:\n",
    "        observation_raw = obs\n",
    "\n",
    "    if config['env_name'].startswith('GDY'):\n",
    "        observation = torch.from_numpy(observation_raw).to(device) / 255.\n",
    "        observation_raw = np.transpose(observation_raw, (1, 2, 0))\n",
    "    else:\n",
    "        observation = torch.from_numpy(np.asarray(observation_raw)).to(device) / 255.\n",
    "        observation_raw = env.raw_last_obs\n",
    "\n",
    "    return observation, observation_raw\n",
    "\n",
    "episodic_memory.reset()\n",
    "num_actions = min(10, env.action_space.n)\n",
    "output_channels = env.observation_space.shape[0]\n",
    "state = env.get_state()\n",
    "observation, observation_raw = process_obs(None)\n",
    "\n",
    "step = 0\n",
    "episode = list()\n",
    "episode_index = 0\n",
    "data = list()\n",
    "while len(data) < 100:\n",
    "    action = torch.randint(num_actions, (1,)).to(device)\n",
    "\n",
    "    next_observation, _, done, info = env.step(0)#action.item())\n",
    "    next_observation, next_observation_raw = process_obs(next_observation)\n",
    "    total_effect = next_observation[-output_channels:] - observation[-output_channels:]\n",
    "    step += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cen_controlled_mask, cen_normal_mask, controlled_embedding, _ = cen_network(observation.unsqueeze(0), action)\n",
    "\n",
    "    cen_controlled_mask_raw = cen_controlled_mask\n",
    "    cen_normal_mask_raw = cen_normal_mask\n",
    "    controlled_embedding = controlled_embedding.cpu().detach().numpy()\n",
    "    episodic_memory.add_item(controlled_embedding.squeeze(0))\n",
    "    reward, distance = score(episodic_memory, controlled_embedding)\n",
    "    print(step, episodic_memory.num, done, reward, distance, cen_controlled_mask.abs().sum())\n",
    "\n",
    "    episode.append(mask_observation(next_observation_raw, cen_controlled_mask_raw.permute(0, 2, 3, 1).squeeze().cpu().numpy()))\n",
    "\n",
    "    if 'ale.lives' in info:\n",
    "        done = ('needs_reset' in info and info['needs_reset']) or info['ale.lives'] == 0\n",
    "    \n",
    "    if done or len(episode) >= 500:\n",
    "        next_observation, next_observation_raw = process_obs(None)\n",
    "        episode = list()\n",
    "        step = 0\n",
    "        episodic_memory.reset()\n",
    "\n",
    "    if not done:\n",
    "        if reward:\n",
    "            # if len([event for event in info[0]['History'] if event['SourceObjectName'] == 'catcher' and event['DestinationObjectName'] == 'butterfly']) > 0:\n",
    "            data.append((observation_raw, next_observation_raw, cen_controlled_mask_raw, cen_normal_mask_raw, total_effect, cen_controlled_mask, reward))\n",
    "        \n",
    "    observation = next_observation\n",
    "    observation_raw = next_observation_raw\n",
    "    state = env.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "836aa7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 0.9547341969489741\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2448x1728 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(figsize=(34, 24), ncols=6, nrows=1)\n",
    "\n",
    "index = np.random.randint(len(data))\n",
    "item = data[index]\n",
    "observation = item[0]\n",
    "next_observation = item[1]\n",
    "cen_controlled_mask = item[2].squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "cen_normal_mask = item[3].squeeze().cpu().numpy().squeeze()\n",
    "total_effect = item[4].permute(1, 2, 0).cpu().numpy().squeeze()\n",
    "threshold_cen_controlled_mask = item[5].cpu().numpy().squeeze()\n",
    "reward = item[6]\n",
    "print(index, len(data), reward)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.tick_params(axis=\"both\", which = \"both\", bottom = False, top = False, left=False,right=False, labelleft=False,labelbottom=False)\n",
    "    ax.imshow(np.zeros_like(observation))\n",
    "\n",
    "axes[0].imshow(observation)\n",
    "axes[1].imshow(next_observation)\n",
    "axes[2].imshow(total_effect)\n",
    "axes[3].imshow(cen_controlled_mask)\n",
    "axes[4].imshow(mask_observation(observation, threshold_cen_controlled_mask))\n",
    "axes[5].imshow(mask_observation(observation, (np.abs(cen_normal_mask) > 0.01).max(axis=0)[None].transpose(1, 2, 0)))\n",
    "\n",
    "\n",
    "axes[0].xaxis.set_label_position('top')\n",
    "axes[1].xaxis.set_label_position('top')\n",
    "axes[2].xaxis.set_label_position('top')\n",
    "axes[3].xaxis.set_label_position('top')\n",
    "axes[4].xaxis.set_label_position('top')\n",
    "axes[5].xaxis.set_label_position('top')\n",
    "\n",
    "axes[0].set_xlabel('Current', color='black', fontsize=48., labelpad=10.)\n",
    "axes[1].set_xlabel('Next', color='black', fontsize=48., labelpad=10.)\n",
    "axes[2].set_xlabel('Total effects', color='black', fontsize=48., labelpad=10.)\n",
    "axes[3].set_xlabel('Controlled raw', color='black', fontsize=48., labelpad=10.)\n",
    "axes[4].set_xlabel('Controlled (ours)', color='black', fontsize=48., labelpad=10.)\n",
    "axes[5].set_xlabel('Normal (ours)', color='black', fontsize=48., labelpad=10.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9888688-e743-443e-8a1a-0f8e66157974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config['ir_eps'], episodic_memory.psi, episodic_memory.running_sum, episodic_memory.running_num, episodic_memory.running_sum / episodic_memory.running_num)\n",
    "print([a / episodic_memory.running_sum / episodic_memory.running_num for a in [36.72447025, 51.56625667, 37.82957517, 35.38434044, 51.75093315]])\n",
    "print([np.maximum(a / 5 - episodic_memory.psi, 0) for a in [36.72447025, 51.56625667, 37.82957517, 35.38434044, 51.75093315]])\n",
    "dists = [\n",
    "    [0.10474112, 0.11980707, 0.09517369, 0.07783488, 0.14415991], #[1.10009527, 1.24710443, 1.00673905, 0.8375519 , 1.48473237],\n",
    "    [3.8995541,  5.47874866, 4.01713939, 3.75696172, 5.49839859], #[36.72447025, 51.56625667, 37.82957517, 35.38434044, 51.75093315],\n",
    "]\n",
    "for i, dist in enumerate(dists):\n",
    "    for eps in [1.0, 0.1, 0.01, 0.001]:\n",
    "        print(i, eps, [(eps / (eps + d), 1 / (np.sqrt(np.sum(eps / (eps + d))) + episodic_memory.C)) for d in dist])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f506a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b51597-4b0f-43ac-8cde-7944c4870776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c21564889880adfba7ced779c85d12a02b1e67e03f74b139a81de66cb5a68e05"
  },
  "kernelspec": {
   "display_name": "cen_rl",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
